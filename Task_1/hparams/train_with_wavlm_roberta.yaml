# ########################################
# ########################################
# Emotion recognition from speech using wav2vec2
#  * Authors: Jarod Duret
# ########################################

# Seed needs to be set at top of yaml, before objects with parameters are made
seed: 1993
__set_seed: !apply:torch.manual_seed [!ref <seed>]

# Dataset will be downloaded to the `data_original`
data_folder: !PLACEHOLDER  # e.g., /path/to/IEMOCAP_full_release
model_name: !PLACEHOLDER
output_folder: !ref results/msp/<seed>/<model_name>
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt

wav2vec2_hub: microsoft/wavlm-large
wav2vec2_folder: !ref <save_folder>/wavlm_checkpoint

roberta_hub: FacebookAI/roberta-base
roberta_folder: !ref <save_folder>/roberta_checkpoint

# Path where data manifest files will be stored
train_annotation: !ref <output_folder>/train.json
valid_annotation: !ref <output_folder>/valid.json
# test_annotation: !ref <output_folder>/test.json
splits: ["train", "valid"]
filter_keys: ["X", "O"]
upsample: False
upsampling_distribution: null
skip_prep: False

sample_rate: 16000
# Speed perturbation
speed_changes: [95, 100, 105]  # List of speed changes for time-stretching

weighted: False
loss_weight: !new:torch.Tensor
    data: [3.2, 3.5, 6.4, 9.0, 1.1, 1.0, 2.5, 5.1]

# speed_perturb: !new:speechbrain.augment.time_domain.SpeedPerturb
#    orig_freq: !ref <sample_rate>
#    speeds: !ref <speed_changes>

# # Frequency drop: randomly drops a number of frequency bands to zero.
# drop_freq_low: 0  # Min frequency band dropout probability
# drop_freq_high: 1  # Max frequency band dropout probability
# drop_freq_count_low: 1  # Min number of frequency bands to drop
# drop_freq_count_high: 3  # Max number of frequency bands to drop
# drop_freq_width: 0.05  # Width of frequency bands to drop

# drop_freq: !new:speechbrain.augment.time_domain.DropFreq
#    drop_freq_low: !ref <drop_freq_low>
#    drop_freq_high: !ref <drop_freq_high>
#    drop_freq_count_low: !ref <drop_freq_count_low>
#    drop_freq_count_high: !ref <drop_freq_count_high>
#    drop_freq_width: !ref <drop_freq_width>

# # Time drop: randomly drops a number of temporal chunks.
# drop_chunk_count_low: 1  # Min number of audio chunks to drop
# drop_chunk_count_high: 5  # Max number of audio chunks to drop
# drop_chunk_length_low: 500 #1000  # Min length of audio chunks to drop
# drop_chunk_length_high: 1000 #2000  # Max length of audio chunks to drop

# drop_chunk: !new:speechbrain.augment.time_domain.DropChunk
#    drop_length_low: !ref <drop_chunk_length_low>
#    drop_length_high: !ref <drop_chunk_length_high>
#    drop_count_low: !ref <drop_chunk_count_low>
#    drop_count_high: !ref <drop_chunk_count_high>

# # Augmenter: Combines previously defined augmentations to perform data augmentation
# wav_augment: !new:speechbrain.augment.augmenter.Augmenter
#    parallel_augment: False
#    concat_original: False
#    repeat_augment: 1
#    shuffle_augmentations: False
#    min_augmentations: 4
#    max_augmentations: 4
#    augment_prob: 1.0
#    augmentations: [
#       !ref <speed_perturb>,
#       !ref <drop_freq>,
#       !ref <drop_chunk>]

# The train logger writes training statistics to a file, as well as stdout.
train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>

ckpt_interval_minutes: 60 # save checkpoint every N min

# Training parameters
number_of_epochs: 10
batch_size: 8
lr: 0.00001
lr_wav2vec2: 0.00001
lr_roberta: 0.00001

#freeze all wav2vec2
freeze_wav2vec2: False
#set to true to freeze the CONV part of the wav2vec2 model
# We see an improvement of 2% with freezing CNNs
freeze_wav2vec2_conv: True

#freeze roberta
freeze_roberta: False 

speech_encoder_dim: 1024
text_encoder_dim: 768
out_encoder_dim: 1792

# Number of emotions
out_n_neurons: 8 # A=Anger, C= Contempt, D= Disgust, F= Fear, H= Happiness, N= Neutral, S= Sadness, U= Surprise. (X= No agreement, O= Other) 

dataloader_options:
    batch_size: !ref <batch_size>
    shuffle: True
    num_workers: 4  # 2 on linux but 0 works on windows
    drop_last: False

# Wav2vec2 encoder
wav2vec2: !new:speechbrain.lobes.models.huggingface_transformers.hubert.HuBERT
    source: !ref <wav2vec2_hub>
    output_norm: True
    freeze: !ref <freeze_wav2vec2>
    freeze_feature_extractor: !ref <freeze_wav2vec2_conv>
    save_path: !ref <wav2vec2_folder>

# RoBERTa encoder
roberta: !new:speechbrain.lobes.models.huggingface_transformers.roberta.RoBERTa
    source: !ref <roberta_hub>
    output_norm: True
    freeze: !ref <freeze_roberta>
    save_path: !ref <roberta_folder>

speech_pooling: !new:speechbrain.nnet.pooling.AttentionPooling
    input_dim: !ref <speech_encoder_dim>

text_pooling: !new:speechbrain.nnet.pooling.AttentionPooling
    input_dim: !ref <text_encoder_dim>

output_mlp: !new:speechbrain.nnet.linear.Linear
    input_size: !ref <out_encoder_dim>
    n_neurons: !ref <out_n_neurons>
    bias: False

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <number_of_epochs>

modules:
    wav2vec2: !ref <wav2vec2>
    roberta: !ref <roberta>
    output_mlp: !ref <output_mlp>
    speech_pooling: !ref <speech_pooling>
    text_pooling: !ref <text_pooling>

model: !new:torch.nn.ModuleList
    - [!ref <output_mlp>,  !ref <speech_pooling>, !ref <text_pooling>]

log_softmax: !new:speechbrain.nnet.activations.Softmax
    apply_log: True

compute_cost: !name:speechbrain.nnet.losses.nll_loss

error_stats: !name:speechbrain.utils.metric_stats.MetricStats
    metric: !name:speechbrain.nnet.losses.classification_error
        reduction: batch

error_stats_f1: !name:speechbrain.utils.metric_stats.SklearnMetricStats

opt_class: !name:torch.optim.Adam
    lr: !ref <lr>

wav2vec2_opt_class: !name:torch.optim.Adam
    lr: !ref <lr_wav2vec2>

roberta_opt_class: !name:torch.optim.Adam
    lr: !ref <lr_roberta>

lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler
    initial_value: !ref <lr>
    improvement_threshold: 0.0025
    annealing_factor: 0.9
    patient: 0

lr_annealing_wav2vec2: !new:speechbrain.nnet.schedulers.NewBobScheduler
    initial_value: !ref <lr_wav2vec2>
    improvement_threshold: 0.0025
    annealing_factor: 0.9

lr_annealing_roberta: !new:speechbrain.nnet.schedulers.NewBobScheduler
    initial_value: !ref <lr_roberta>
    improvement_threshold: 0.0025
    annealing_factor: 0.9

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>
    recoverables:
        model: !ref <model>
        wav2vec2: !ref <wav2vec2>
        roberta: !ref <roberta>
        lr_annealing_output: !ref <lr_annealing>
        lr_annealing_wav2vec2: !ref <lr_annealing_wav2vec2>
        lr_annealing_roberta: !ref <lr_annealing_roberta>
        counter: !ref <epoch_counter>
